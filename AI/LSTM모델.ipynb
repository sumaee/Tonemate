{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pip install librosa\n","# pip install keras\n","# pip install tensorflow\n","# pip install os"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":350,"status":"ok","timestamp":1678682363382,"user":{"displayName":"박정희[서울_ 6반_ A604]팀원","userId":"17919197066029500351"},"user_tz":-540},"id":"XdEP3n74AnWJ"},"outputs":[],"source":["import os\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from keras.models import load_model\n","\n","import module.lstm as LSTM_MODEL\n","import module.preprocess as PROCESSING"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["encoder = LabelEncoder()\n","FEATURES = \"MFCC20_ALL\"\n","ROOT = \"D:/DATA\"\n","SR = 16000\n","TARGET_EPOCH = 0\n","PLUS_EPOCH = 10\n","MODEL_VERSION = \"V1\"\n","\n","TRAIN_PATH = f\"{ROOT}/train\"\n","VAL_PATH = f\"{ROOT}/val\"\n","TENSER_PATH = f\"{ROOT}/tensor/{FEATURES}\"\n","CHECKPOINT_PATH = f\"{ROOT}/checkpoint/{MODEL_VERSION}\"\n","CHECK_POINT_FILE = f\"{FEATURES}/checkpoint{TARGET_EPOCH}.h5\"\n","REPLACE_FILE = f\"{FEATURES}/checkpoint{(TARGET_EPOCH+PLUS_EPOCH)}.h5\""]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["#wav파일들을 npy파일들로 변환하기\n","# X, y = PROCESSING.createDATA(\"D:/ToneMate_wav\",SR,20,True,True,True,True,True)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# npy모두 합쳐서 학습데이터 생성하기\n","X = []\n","y = []\n","\n","singer_g = []\n","title_g = []\n","mean_g = []\n","var_g = []\n","dict_singer_id = dict()\n","id_cnt = 1\n","for root, dirs, files in os.walk(\"D:/ToneMate_numpy\"):\n","    for file in files:\n","        if file.endswith(\".npy\"):\n","            label = file.split(\" - \")\n","            singer = label[0]\n","            title = label[1][:-4]\n","            path = os.path.join(root, file) \n","            data = np.load(path)\n","            if(data.shape[0]==36 and data.shape[1]==3000):\n","                if singer not in dict_singer_id:\n","                    dict_singer_id[singer] = id_cnt\n","                    id_cnt += 1\n","\n","                X.append(data)\n","                y.append(singer)\n","                \n","                data_mean = [round(attr, 5) for attr in data.mean(axis=1)]\n","                data_var = [round(attr, 5) for attr in data.var(axis=1)]\n","                singer_g.append(singer)\n","                title_g.append(title)\n","                mean_g.append(data_mean)\n","                var_g.append(data_var)\n","                \n","\n","X = np.stack(X)\n","y = np.array(y)\n","mean_g = np.stack(mean_g)\n","var_g = np.stack(var_g)\n","\n","#표준화\n","mean_g_mean_by_col = mean_g.mean(axis=0)\n","mean_g_std_by_col = mean_g.std(axis=0)\n","var_g_mean_by_col = var_g.mean(axis=0)\n","var_g_std_by_col = var_g.std(axis=0)\n","\n","mean_g = (mean_g-mean_g_mean_by_col)/mean_g_std_by_col\n","var_g = (var_g-var_g_mean_by_col)/var_g_std_by_col\n","\n","if not os.path.exists(TENSER_PATH):\n","    os.makedirs(TENSER_PATH)\n","\n","np.save(f'{TENSER_PATH}/X.npy', X)\n","np.save(f'{TENSER_PATH}/y.npy', y)\n","np.save(f'{TENSER_PATH}/mean_g_mean_by_col.npy', mean_g_mean_by_col)\n","np.save(f'{TENSER_PATH}/mean_g_std_by_col.npy', mean_g_std_by_col)\n","np.save(f'{TENSER_PATH}/var_g_mean_by_col.npy', var_g_mean_by_col)\n","np.save(f'{TENSER_PATH}/var_g_std_by_col.npy', var_g_std_by_col)\n","\n","init_song_sql = \"INSERT INTO song (singer_id, title, mfcc_mean, mfcc_var,  rms_mean, rms_var, spc_mean, spc_var, spr_mean, spr_var, stft_mean, stft_var, zcr_mean, zcr_var) VALUES \"\n","init_singer_sql = \"INSERT INTO singer (singer_id,name) VALUES \"\n","\n","for i in range(len(singer_g)):\n","    mfcc_mean, mfcc_var = mean_g[i][:20].mean(),var_g[i][:20].mean()\n","    stft_mean, stft_var = mean_g[i][20:32].mean(), var_g[i][20:32].mean()\n","    zcr_mean,zcr_var = mean_g[i][32],var_g[i][32] \n","    spc_mean,spc_var = mean_g[i][33],var_g[i][33]\n","    spr_mean, spr_var = mean_g[i][34],var_g[i][34]\n","    rms_mean, rms_var = mean_g[i][35],var_g[i][35]\n","    init_song_sql += f\"({dict_singer_id[singer_g[i]]}, '{title_g[i]}', {mfcc_mean}, {mfcc_var},  {rms_mean}, {rms_var}, {spc_mean}, {spc_var}, {spr_mean}, {spr_var}, {stft_mean}, {stft_var}, {zcr_mean}, {zcr_var}),\"\n","    \n","for key,value in dict_singer_id.items():\n","    init_singer_sql += f\"({value},'{key}'),\"\n","    \n","init_song_sql = init_song_sql[:-1]+\";\"\n","init_singer_sql = init_singer_sql[:-1]+\";\"\n","\n","with open(f'{TENSER_PATH}/init.sql', 'w',  encoding=\"UTF-8\") as f:\n","    f.write(\"use tonemate;\\n\")\n","    f.write(\"delete from song;\\n\")\n","    f.write(\"delete from singer;\\n\")\n","    f.write(init_song_sql) \n","    f.write(\"\\n\")\n","    f.write(init_singer_sql)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, y = np.load(f'{TENSER_PATH}/X.npy'), np.load(f'{TENSER_PATH}/y.npy')\n","X = np.transpose(X, (0, 2, 1))\n","encoder = encoder.fit(y)\n","X_train, X_valid, y_train, y_valid = train_test_split(X, encoder.transform(y), test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1039,"status":"error","timestamp":1678683649636,"user":{"displayName":"박정희[서울_ 6반_ A604]팀원","userId":"17919197066029500351"},"user_tz":-540},"id":"CV0F1lEjA8NZ","outputId":"169af07d-139b-4957-ca79-ed2db1b787d7"},"outputs":[],"source":["model = LSTM_MODEL.create_lstm_model(len(encoder.classes_),sr = SR,feature_size=X.shape[2])\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","checkpoint_callback = LSTM_MODEL.Checkpoint(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n","\n","\n","if os.path.isfile(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\"):\n","    model = load_model(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n","    #model.load_weights(f\"{CHECKPOINT_PATH}/{CHECK_POINT_FILE}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not os.path.exists(f\"{CHECKPOINT_PATH}/{FEATURES}\"):\n","    os.makedirs(f\"{CHECKPOINT_PATH}/{FEATURES}\")\n","\n","model.fit(X_train, to_categorical(y_train,num_classes=len(encoder.classes_)), epochs= (TARGET_EPOCH+PLUS_EPOCH), validation_data=(X_valid, to_categorical(y_valid,num_classes=len(encoder.classes_))), callbacks=[checkpoint_callback], initial_epoch=TARGET_EPOCH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pred = model.predict(test_wav)\n","# top_5 = np.argsort(pred, axis=1)[:, -5:]\n","# top_5_labels = encoder.inverse_transform(top_5.T.ravel())"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPpGMfcfPDp4HDDzqJ8ps/W","mount_file_id":"1_bkXPhS_naITQMrL-bxV2HURkeuDjXST","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
